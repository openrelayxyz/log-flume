Description: A  pool of flume servers for Ether Cattle

Parameters:
  FlumeDiskSize:
    Default: '850'
    Description: Size of each node's chaindata storage volume in GiB
    MinValue: '8'
    Type: Number
  FlumeDiskIOPS:
    Default: '3000'
    Description: Size of each node's chaindata storage volume in GiB
    MinValue: '3000'
    MaxValue: '16000'
    Type: Number
  FlumeImageAMI:
    Default: ""
    Description: Custom AMI to use for the flume servers, empty string for default AWS AMI image
    Type: String
  S3FlumeBackup:
    Default: flume-stage-db/mainnet/logs-20200216.sqlite.lz4
    Type: String
    Description: "The backup bucket with path for the current backup. Do not include s3:// as that is provided in code"
  S3FlumeBackupBucket:
    Default: flume-stage-db
    Type: String
    Description: The bucket for Flume to store backups in
  S3FlumeBinaryDirectory:
    Default: flume/kafka-feeds-1
    Type: String
    Description: The bucket containing Flume Binaries
  S3ECBucketName:
    Default: ethercattle-binaries
    Type: String
    Description: The bucket containing EtherCattle Binaries
  InfrastructureStack:
    Type: String
    Description: The infrastructure stack this cluster connects to
  KeyName:
    Type: AWS::EC2::KeyPair::KeyName
    Description: The name of the SSH key pair allowed to SSH into the nodes
  NetworkId:
    Type: String
    Description: An identifier for the network this cluster represents. This should be common across all clusters representing the same network. (this is a subdirectory backups/snapshots will be stored)
  FlumeNetworkFlag:
    Type: String
    AllowedValues:
      - "--mainnet"
      - "--classic"
      - "--goerli"
      - "--ropsten"
      - "--rinkeby"
    Default: "--mainnet"
    Description: The Flume network flag
  FlumeClusterVersion:
    Type: String
    Default: v0.1
    Description: The cluster version for flume, to be used in service discovery queries
  FlumeSyncEndpoint:
    Default: ws://localhost:5654
    Type: String
    Description: Endpoint Flume connects to do sync with kafka:// or ws:// or wss:// endpoints accepted.
  FlumeTargetCapacity:
    Type: Number
    Default: 2
    Description: Minimum number of instances for flume
  FlumeMaxCapacity:
    Type: Number
    Default: 5
    Description: Maximum number of instances for flume
  FlumeOnDemandPercentage:
    Type: Number
    Default: 0
    Description: The percentage (0 - 100) of flume that should be on-demand instead of spot instances.
  FlumeCPUScalingTargetValue:
    Type: Number
    Default: 80
    Description: The percentage (0 - 100) CPU utilization target for auto scaling flume
  FlumeSize:
    Type: String
    Description: Whether to use full size flume or smaller ones. Use "small" if you expect a small request volume.
    AllowedValues:
      - full
      - small
    Default: full
  FlumeProcessorArchitecture:
    Type: String
    Description: Whether to use ARM64 or AMD64 instance types
    AllowedValues:
      - arm64
      - amd64
    Default: arm64
  FlumeAlternateTargetGroup:
    Type: String
    Description: An alternative comma-separated list of target groups that flume should be assigned to.
  NotificationEmail:
    Type: String
    Description: An optional e-mail address to receive notifications from alarms
  AlarmSNSTopic:
    Type: String
    Description: An optional SNS topic to receive notifications from alarms
  FlumeExtraSecurityGroup:
    Type: String
    Description: An additional security to be assigned to Flumes. Leave this blank unless you need to add additional connectivity rules.
  FlumeSnapshotScheduleExpression:
    Type: String
    Description: A schedule expression for the frequency to take snapshots
    Default: "cron(55 4 * * ? *)"
  FlumeSpotAllocationStrategy:
    Type: String
    AllowedValues:
      - "lowest-price"
      - "capacity-optimized"
    Default: "capacity-optimized"
  ConsulEc2RetryTagKey:
    Description:
      The EC2 instance tag key to filter on when joining to other Consul
      nodes.
    Type: String
    Default: "rivet-consul-cluster"
    ConstraintDescription: Must match EC2 Tag Name requirements.
  ConsulEc2RetryTagValue:
    Description:
      The EC2 instance tag value to filter on when joining to other Consul
      nodes.
    Type: String
    Default: "rivet-consul-member"
    ConstraintDescription: Must match EC2 Tag Name requirements.
  ConsulPrimaryRegion:
      Description: The AWS region of the primary Consul cluster. If not set, defaults to this region.
      Type: String
  ConsulAccountName:
      Type: String
      Description: Datacenter prefix for consul
  ConsulCIDRBlock:
    Description: The CIDR Block of Consul clients that may connect to these services.
    Default: 10.255.255.255/32
    Type: String
  FlumeKafkaRollback:
    Description: The number of Kafka messages to roll back upon resumption
    Type: Number
    Default: 5000
  FlumeReorgThreshold:
    Description: The minimum number of blocks to have in memory for re-orging
    Type: Number
    Default: 128
  UrgentAlarmWebhook:
    Description: URL for webhooks pertaining to urgent alarms
    Type: String
  WarningAlarmWebhook:
    Description: URL for webhooks pertaining to warning alarms
    Type: String
  SnapshotTimestamp:
    Description: The time the last timestamp was taken (this is managed by the stack and can be ignored)
    Default: 0
    Type: Number

Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: Infrastructure
        Parameters:
          - InfrastructureStack
          - FlumeAlternateTargetGroup
          - AlarmSNSTopic
          - NotificationEmail
          - KeyName
          - FlumeSnapshotScheduleExpression
          - FlumeProcessorArchitecture
      - Label:
          default: Cluster
        Parameters:
          - NetworkId
          - S3FlumeBackup

      - Label:
          default: Flume
        Parameters:
          - FlumeDiskSize
          - FlumeSize
          - FlumeImageAMI
          - FlumeSyncEndpoint
          - FlumeTargetCapacity
          - FlumeMaxCapacity
          - FlumeOnDemandPercentage
          - SnapshotValidationThreshold
          - FlumeExtraSecurityGroup
          - FlumeSpotAllocationStrategy
      - Label:
          default: Fallback
        Parameters:
          - FallbackTargetCapacity
          - FallbackMaxCapacity
    ParameterLabels:
      FlumeDiskSize:
        default: Disk Size
      FlumeImageAMI:
        default: Flume AMI Image
      S3FlumeBackup:
        default: S3 Flume Backup
      S3ECBucketName:
        default: S3 EtherCattle Bucket
      InfrastructureStack:
        default: Infrastructure CloudFormation Stack
      KeyName:
        default: SSH Key Pair
      NetworkId:
        default: Unique Network ID
      FlumeSyncEndpoint:
        default: Flume Sync Endpoint
      FlumeTargetCapacity:
        default: Target Capacity
      FlumeOnDemandPercentage:
        default: On-Demand Percentage
      FlumeExtraSecurityGroup:
        default: Flume Extra Security Group
      FlumeAlternateTargetGroup:
        default: Alternate Target Group
      NotificationEmail:
        default: Notification Email Address
      AlarmSNSTopic:
        default: SNS Topic for Alarms
      SnapshotValidationThreshold:
        default: Snapshot Validation Threshold
      FlumeSnapshotScheduleExpression:
        default: Snapshot Schedule Expression

Mappings:
  InstanceSizes:
    amd64:
      full:
        - InstanceType: i3en.large
        - InstanceType: m5.xlarge
        - InstanceType: m5a.xlarge
        - InstanceType: m5ad.xlarge
        - InstanceType: m5d.xlarge
        - InstanceType: r5.large
        - InstanceType: r5a.large
        - InstanceType: r5ad.large
        - InstanceType: r5d.large
      small:
        - InstanceType: t3.medium
        - InstanceType: t3a.medium
    arm64:
      full:
        - InstanceType: r6g.large
        - InstanceType: r6gd.large
        - InstanceType: m6g.xlarge
        - InstanceType: m6gd.xlarge
      small:
        - InstanceType: t4g.medium
        - InstanceType: m6g.medium
        - InstanceType: m6gd.medium
        - InstanceType: c6g.large
        - InstanceType: c6gd.large
        - InstanceType: c6gn.large
        - InstanceType: a1.large
  PoolSize:
    amd64:
      full: 11
      small: 6
    arm64:
      full: 8
      small: 12
  RegionMap:
    us-west-1:
      arm64: ami-06da41549f55c94e2
      amd64: ami-034bf895b736be04a
    eu-central-1:
      arm64: ami-0ae8199ab6970fbab
      amd64: ami-0bb75d95f668ff5a7
    us-east-1:
      arm64: ami-0b250ac7d54af0ad8
      amd64: ami-011899242bb902164
    ap-northeast-2:
      arm64: ami-09517426951d1f0b3
      amd64: ami-0de358223fd8dc276
    sa-east-1:
      arm64: ami-0199924b6c357b2ae
      amd64: ami-04ef59610885412b7
    ap-northeast-1:
      arm64: ami-0a276f4ab43f64268
      amd64: ami-08c925c2f4fe5aee0
    ap-southeast-1:
      arm64: ami-0a5fb7e26a54b13b8
      amd64: ami-03425fe81e8a82dfb
    us-east-2:
      arm64: ami-00a1c830981a54d96
      amd64: ami-07d5003620a5450ee
    ap-southeast-2:
      arm64: ami-0e3dd8d5a4dc6c4eb
      amd64: ami-0b31ea67df6098216
    eu-west-1:
      arm64: ami-09e31e88ea2c3eb5d
      amd64: ami-04ffbabc7935ec0e9
    eu-north-1:
      arm64: ami-0fefce11d777066fe
      amd64: ami-0000da4d489188a4b
    ap-south-1:
      arm64: ami-011a054cc2d93e8b0
      amd64: ami-097b711d946240d58
    eu-west-3:
      arm64: ami-09d0f429725cccc6d
      amd64: ami-0b209583a4a1146dd
    eu-west-2:
      arm64: ami-06b4a7b9c9ba238e0
      amd64: ami-0d738342f2d2fd5fd
    ca-central-1:
      arm64: ami-0ce37fa160fc53d62
      amd64: ami-0a20346326d3d1853
    us-west-2:
      arm64: ami-063326752a8929b25
      amd64: ami-089668cd321f3cf82



Conditions:
  HasKeyName: !Not [!Equals [!Ref KeyName, '']]
  HasATG: !Not [!Equals [!Ref FlumeAlternateTargetGroup, '']]
  HasNotificationEmail: !Not [!Equals [ !Ref NotificationEmail, "" ]]
  HasSNSTopic: !Not [!Equals [ !Ref AlarmSNSTopic, "" ]]
  HasFlumeImageAMI: !Not [!Equals [ !Ref FlumeImageAMI, "" ]]
  HasExtraSecurityGroup: !Not [!Equals [ !Ref FlumeExtraSecurityGroup, "" ]]
  SmallFlume: !Equals [ !Ref FlumeSize, "small"]
  FlumeSpotLowestPrice: !Equals [!Ref FlumeSpotAllocationStrategy, "lowest-price"]
  SpecifiesConsulRegion: !Not [ !Equals [ !Ref ConsulPrimaryRegion, "" ] ]
  IsArm: !Equals [ !Ref FlumeProcessorArchitecture, "arm64" ]
  HasRollback: !Not [ !Equals [!Ref FlumeKafkaRollback, 0] ]
  HasUrgentWebhook: !Not [ !Equals [ !Ref UrgentAlarmWebhook, "" ]]
  HasWarningWebhook: !Not [ !Equals [ !Ref WarningAlarmWebhook, "" ]]


Resources:
  UrgentNotifications:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Urgent Notifications
  UrgentNotificationsSubscription:
    Type: AWS::SNS::Subscription
    Condition: HasUrgentWebhook
    Properties:
      Endpoint: !Ref UrgentAlarmWebhook
      Protocol: https
      TopicArn: !Ref UrgentNotifications
  WarningNotifications:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Warning Notifications
  WarningNotificationsSubscription:
    Type: AWS::SNS::Subscription
    Condition: HasWarningWebhook
    Properties:
      Endpoint: !Ref WarningAlarmWebhook
      Protocol: https
      TopicArn: !Ref WarningNotifications
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal: {Service: [lambda.amazonaws.com]}
          Action: ['sts:AssumeRole']
      Path: "/"
      ManagedPolicyArns:
      - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
  # Max:
  #   Type: AWS::Lambda::Function
  #   Properties:
  #     Handler: index.handler
  #     Role: !GetAtt LambdaExecutionRole.Arn
  #     Code:
  #       ZipFile: !Sub |
  #         var response = require('./cfn-response');
  #         exports.handler = function(event, context) {
  #           var result = Math.max(parseInt(event.ResourceProperties.Op1), parseInt(event.ResourceProperties.Op2));
  #           response.send(event, context, response.SUCCESS, {Value: result});
  #         };
  #     Runtime: nodejs12.x

  GetBucketName:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Code:
        ZipFile: !Sub |
          var response = require('./cfn-response');
          exports.handler = function(event, context) {
            response.send(event, context, response.SUCCESS, {Name: event.ResourceProperties.ObjectPath.split("/")[0]});
          };
      Runtime: nodejs12.x

  CurrentBackupBucket:
    Type: Custom::GetBucketName
    Properties:
      ServiceToken: !GetAtt GetBucketName.Arn
      ObjectPath: !Ref S3FlumeBackup


  AggregatedNotifications:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Aggregated Notifications
  AggregatedNotificationsSubscription:
    Type: AWS::SNS::Subscription
    Condition: HasNotificationEmail
    Properties:
      Endpoint: !Ref NotificationEmail
      Protocol: email
      TopicArn: !Ref AggregatedNotifications
  FlumeCPUSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Flume CPU
  FlumeDiskSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Flume Disk

  FlumeDiskAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref FlumeDiskSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
        - !If [ HasWarningWebhook, !Ref WarningNotifications, !Ref 'AWS::NoValue' ]
      AlarmDescription: "Alarms when the overlay data directory > 95% full"
      ComparisonOperator: "GreaterThanThreshold"
      Metrics:
        - Id: nvme
          MetricStat:
            Metric:
              MetricName: "disk_used_percent"
              Namespace: CWAgent
              Dimensions:
                - Name: AutoScalingGroupName
                  Value : !Ref FlumeAutoScalingGroup
                - Name: device
                  Value : "nvme2n1"
                - Name: fstype
                  Value : "ext4"
                - Name: path
                  Value : "/var/lib/flume"
            Period: 60
            Stat: Maximum
          Label: NVME Flume Disk Usage
          ReturnData: false
        - Id: ebs
          MetricStat:
            Metric:
              MetricName: "disk_used_percent"
              Namespace: CWAgent
              Dimensions:
                - Name: AutoScalingGroupName
                  Value : !Ref FlumeAutoScalingGroup
                - Name: device
                  Value : "nvme1n1"
                - Name: fstype
                  Value : "ext4"
                - Name: path
                  Value : "/var/lib/flume"
            Period: 60
            Stat: Maximum
          Label: EBS Flume Disk Usage
          ReturnData: false
        - Id: delta
          Expression: "(ebs + nvme)"
      InsufficientDataActions:
        - !Ref FlumeDiskSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
        - !If [ HasWarningWebhook, !Ref WarningNotifications, !Ref 'AWS::NoValue' ]
      EvaluationPeriods: 5
      OKActions:
        - !Ref FlumeDiskSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
        - !If [ HasWarningWebhook, !Ref WarningNotifications, !Ref 'AWS::NoValue' ]
      Threshold: 95
      TreatMissingData: missing
  FlumesCPUAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref FlumeCPUSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
        - !If [ HasUrgentWebhook, !Ref UrgentNotifications, !Ref 'AWS::NoValue' ]
      AlarmDescription: "Alarms when the flume CPU > 80%"
      ComparisonOperator: "GreaterThanThreshold"
      Dimensions:
        - Name: AutoScalingGroupName
          Value : !Ref FlumeAutoScalingGroup
      InsufficientDataActions:
        - !Ref FlumeCPUSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
        - !If [ HasUrgentWebhook, !Ref UrgentNotifications, !Ref 'AWS::NoValue' ]
      EvaluationPeriods: 10
      DatapointsToAlarm: 7
      MetricName: "CPUUtilization"
      Namespace: AWS/EC2
      OKActions:
        - !Ref FlumeCPUSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
        - !If [ HasUrgentWebhook, !Ref UrgentNotifications, !Ref 'AWS::NoValue' ]
      Period: 60
      Statistic: Maximum
      Threshold: 80
      TreatMissingData: missing
  SnapshotAgeWarning:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
        - !If [ HasWarningWebhook, !Ref WarningNotifications, !Ref 'AWS::NoValue' ]
      AlarmDescription: "Alarms when the latest snapshot exceeds a certain age"
      ComparisonOperator: "GreaterThanThreshold"
      EvaluationPeriods: 2
      Metrics:
        - Id: current
          MetricStat:
            Metric:
              MetricName: "UnixTimestamp"
              Namespace: Consul
            Period: 60
            Stat: Maximum
          Label: Unix Timestamp
          ReturnData: false
        - Id: delta
          Expression: !Sub "(current - ${SnapshotTimestamp})"
      OKActions:
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
        - !If [ HasWarningWebhook, !Ref WarningNotifications, !Ref 'AWS::NoValue' ]
      Threshold: 90000 # 25 hours in seconds
      TreatMissingData: breaching
  MetricsConfigParameter:
    Type: "AWS::SSM::Parameter"
    Properties:
      Type: String
      Value: '{"metrics":{"append_dimensions":{"AutoScalingGroupName":"${aws:AutoScalingGroupName}"},"metrics_collected":{"cpu":{"measurement":["cpu_usage_idle","cpu_usage_user","cpu_usage_system"],"metrics_collection_interval":60,"resources":["*"],"totalcpu":false},"disk":{"measurement":["used_percent","inodes_free"],"metrics_collection_interval":60,"resources":["/var/lib/flume","/var/lib/flume/overlay","/"]},"diskio":{"measurement":["io_time"],"metrics_collection_interval":60,"resources":["/var/lib/flume","/var/lib/flume/overlay","/"]},"mem":{"measurement":["mem_used_percent"],"metrics_collection_interval":60},"statsd":{"metrics_aggregation_interval":60,"metrics_collection_interval":10,"service_address":":8125"},"swap":{"measurement":["swap_used_percent"],"metrics_collection_interval":60}}}}'

  FlumeLG:
    Type: AWS::Logs::LogGroup
    Properties:
      RetentionInDays: 7
      LogGroupName:
        "Fn::Sub":
          - "/${ClusterId}/${AWS::StackName}/flume"
          - ClusterId:
              "Fn::ImportValue": !Sub "${InfrastructureStack}-ClusterId"
  FlumeNodeSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Allow internal SSH access and VPC access to RPC
      VpcId:
        "Fn::ImportValue": !Sub "${InfrastructureStack}-VpcId"
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: '22'
        ToPort: '22'
        CidrIp: !Join ["", ["Fn::ImportValue": !Sub "${InfrastructureStack}-VpcBaseIp", ".0.0/14"]]
      - IpProtocol: tcp
        FromPort: '8000'
        ToPort: '8000'
        CidrIp: !Join ["", ["Fn::ImportValue": !Sub "${InfrastructureStack}-VpcBaseIp", ".0.0/16"]]
      - IpProtocol: tcp
        FromPort: '21000'
        ToPort: '21001'
        CidrIp: !Ref ConsulCIDRBlock
      - IpProtocol: udp
        # Consul agent gossip
        FromPort: '8301'
        ToPort: '8301'
        CidrIp: !Ref ConsulCIDRBlock
  FlumeNodeRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
            - autoscaling.amazonaws.com
        Version: '2012-10-17'
  FlumeNodePolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref FlumeNodeRole
      PolicyName: !Sub "FlumeNode${AWS::StackName}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Action:
              - logs:CreateLogStream
              - logs:CreateLogGroup
              - logs:PutLogEvents
            Effect: Allow
            Resource: "*"
            Sid: Stmt3
          - Action:
              - s3:GetObject
              - s3:ListBucket
              - s3:GetBucketPolicy
              - s3:GetObjectTagging
              - s3:GetBucketLocation
            Resource:
              - !Sub arn:aws:s3:::${S3FlumeBackupBucket}
              - !Sub arn:aws:s3:::${S3FlumeBackupBucket}/*
            Effect: Allow
          - Action:
              - s3:GetObject
              - s3:ListBucket
              - s3:GetBucketPolicy
              - s3:GetObjectTagging
              - s3:GetBucketLocation
            Resource:
              - !Sub arn:aws:s3:::${CurrentBackupBucket.Name}
              - !Sub arn:aws:s3:::${S3FlumeBackup}/*
            Effect: Allow
          - Action:
              - s3:GetObject
              - s3:ListBucket
              - s3:GetBucketPolicy
              - s3:GetObjectTagging
              - s3:GetBucketLocation
            Resource:
              - !Sub arn:aws:s3:::${S3ECBucketName}
              - !Sub arn:aws:s3:::${S3ECBucketName}/*
            Effect: Allow
          - Action:
              - cloudwatch:PutMetricData
              - ec2:DescribeTags
              - ec2:DescribeInstances
              - logs:PutLogEvents
              - logs:DescribeLogStreams
              - logs:DescribeLogGroups
              - logs:CreateLogStream
              - logs:CreateLogGroup
            Resource: "*"
            Effect: Allow
          - Action:
              - ssm:GetParameter
            Resource: !Sub "arn:aws:ssm:*:*:parameter/${MetricsConfigParameter}"
            Effect: Allow
          - Action:
              - sns:Publish
            Resource:
              - !Ref AggregatedNotifications
              - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
            Effect: Allow
          - Action:
              - ec2:ModifyVolume
              - ec2:DescribeVolumes
            Effect: Allow
            Resource: "*"
  FlumeNodeInstanceProfile:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      Path: /
      Roles:
      - !Ref FlumeNodeRole
    DependsOn: FlumeNodeRole
  FlumeLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Metadata:
      AWS::CloudFormation::Init:
          configSets:
            cs_install:
              - install_and_enable_cfn_hup
              - create_consul_group_user_dir
              - install_consul
              - install_consul_template
              - consul_bootstrap
          install_and_enable_cfn_hup:
            files:
              /etc/cfn/cfn-hup.conf:
                content: !Join
                  - ""
                  - - |
                      [main]
                    - stack=
                    - !Ref "AWS::StackId"
                    - |+
                    - region=
                    - !Ref "AWS::Region"
                    - |+
                mode: "000400"
                owner: root
                group: root
              /etc/cfn/hooks.d/cfn-auto-reloader.conf:
                content: !Join
                  - ""
                  - - |
                      [cfn-auto-reloader-hook]
                    - |
                      triggers=post.update
                    - >
                      path=Resources.FlumeLaunchTemplate.Metadata.AWS::CloudFormation::Init
                    - "action=/usr/local/bin/cfn-init -v "
                    - "         --stack "
                    - !Ref "AWS::StackName"
                    - "         --resource FlumeLaunchTemplate "
                    - "         --configsets cs_install "
                    - "         --region "
                    - !Ref "AWS::Region"
                    - |+
                    - |
                      runas=root
              /lib/systemd/system/cfn-hup.service:
                content: !Join
                  - ""
                  - - |
                      [Unit]
                    - |+
                      Description=cfn-hup daemon
                    - |
                      [Service]
                    - |
                      Type=simple
                    - |
                      ExecStart=/usr/local/bin/cfn-hup
                    - |+
                      Restart=always
                    - |
                      [Install]
                    - WantedBy=multi-user.target
            commands:
              01enable_cfn_hup:
                command: systemctl enable cfn-hup.service
              02start_cfn_hup:
                command: systemctl start cfn-hup.service
          create_consul_group_user_dir:
            users:
              consul:
                homeDir: /srv/consul
            commands:
              01_create_data_dir:
                command: mkdir -p /opt/consul/data
          install_consul:
            sources:
              /usr/bin/: !Sub https://releases.hashicorp.com/consul/1.9.1/consul_1.9.1_linux_${FlumeProcessorArchitecture}.zip
          install_consul_template:
            sources:
              /usr/bin/: !Sub https://releases.hashicorp.com/consul-template/0.24.0/consul-template_0.24.0_linux_${FlumeProcessorArchitecture}.zip
          consul_bootstrap:
            files:
              /opt/consul/config/client.json:
                content:
                  Fn::Sub:
                    - |
                      {
                        "advertise_addr": "PrivateIpAddress",
                        "bind_addr": "PrivateIpAddress",
                        "node_name": "InstanceId",
                        "datacenter": "${ConsulAccountName}--${AWS::Region}",
                        "server": false,
                        "ui" : false,
                        "leave_on_terminate" : true,
                        "skip_leave_on_interrupt" : false,
                        "disable_update_check": true,
                        "log_level": "warn",
                        "enable_local_script_checks": true,
                        "data_dir": "/opt/consul/data",
                        "client_addr": "0.0.0.0",
                        "primary_datacenter": "${PrimaryRegion}",
                        "retry_join": ["provider=aws region=${AWS::Region} tag_key=${ConsulEc2RetryTagKey} tag_value=${ConsulEc2RetryTagValue}"],
                        "addresses": {
                          "http": "0.0.0.0"
                        },
                        "ports": {"grpc": 8502 },
                        "connect": {
                          "enabled": true
                        }
                      }
                    - PrimaryRegion: !If [ SpecifiesConsulRegion, !Ref ConsulPrimaryRegion, !Sub "${AWS::Region}"]
                mode: 000644
              /opt/consul/config/flume.json:
                content: !Sub |
                  {
                    "service": {
                      "name": "${NetworkId}-flume",
                      "tags": [
                        "${NetworkId}",
                        "flume",
                        "${FlumeClusterVersion}"
                      ],
                      "port": 8000,
                      "weights": { "passing": 1, "warning": 0 },
                      "connect": {
                        "sidecar_service": {
                          "proxy": {
                            "upstreams": [
                              {
                                "destination_name": "${NetworkId}-replica-ws",
                                "local_bind_port": 7546
                              }
                            ]
                          }
                        }
                      },
                      "check": {
                        "args": ["curl", "-f", "http://localhost:8000"],
                        "interval": "2s"
                      }
                    }
                  }
                mode: 000644
              /etc/systemd/system/consul.service:
                content: !Join
                  - ""
                  - - |
                      [Unit]
                    - |
                      Description="HashiCorp Consul - A service mesh solution"
                    - |
                      Documentation=https://www.consul.io/
                    - |
                      Requires=network-online.target
                    - |
                      After=network-online.target
                    - |
                      ConditionFileNotEmpty=/opt/consul/config/client.json
                    - |+
                      [Service]
                    - |
                      Type=notify
                    - |
                      User=consul
                    - |
                      Group=consul
                    - |
                      ExecStart=/usr/bin/consul agent -config-dir /opt/consul/config -data-dir /opt/consul/data
                    - |
                      ExecReload=/usr/bin/consul reload
                    - |
                      KillMode=process
                    - |
                      Restart=on-failure
                    - |
                      TimeoutSec=300s
                    - |
                      LimitNOFILE=65536
                    - |+
                      [Install]
                    - WantedBy=multi-user.target
              /etc/systemd/system/flume-sidecar.service:
                content: !Join
                  - ""
                  - - |
                      [Unit]
                    - |
                      Description="Flume Sidecar Service"
                    - |
                      Documentation=https://www.consul.io/
                    - |
                      Requires=consul.service
                    - |
                      After=network-online.target
                    - |
                      ConditionFileNotEmpty=/opt/consul/config/flume.json
                    - |+
                      [Service]
                    - |
                      Type=simple
                    - |
                      User=consul
                    - |
                      Group=consul
                    - !Sub |
                      ExecStart=/usr/bin/consul connect envoy -sidecar-for ${NetworkId}-flume
                    - |
                      ExecReload=/usr/bin/consul reload
                    - |
                      KillMode=process
                    - |
                      Restart=on-failure
                    - |
                      TimeoutSec=300s
                    - |
                      LimitNOFILE=65536
                    - |+
                      [Install]
                    - WantedBy=multi-user.target
            commands:
              00_fill_consul_config_ip:
                command: myip=`echo $(curl -s http://169.254.169.254/latest/meta-data/local-ipv4)` && sed -i "s/PrivateIpAddress/${myip}/g" /opt/consul/config/client.json
              01_fill_consul_config_instance_id:
                command: myid=`echo $(curl -s http://169.254.169.254/latest/meta-data/instance-id)` && sed -i "s/InstanceId/${myid}/g" /opt/consul/config/client.json
              02_change_ownership:
                command: chown -R consul:consul /opt/consul
              03_reload_systemd:
                command: systemctl daemon-reload
              04_enable_consul:
                command: systemctl enable consul
              05_start_consul:
                command: systemctl start consul
              06_fetch_envoy:
                command: !Sub aws s3 cp s3://${S3ECBucketName}/envoy/v1.16.0/envoy-${FlumeProcessorArchitecture} /usr/bin/envoy
              07_install_envoy:
                command: chmod +x /usr/bin/envoy
              08_enable_flume_sidecar:
                command: systemctl enable flume-sidecar
              09_start_flume_sidecar:
                command: systemctl start flume-sidecar
    Properties:
      LaunchTemplateData:
        ImageId: !If [HasFlumeImageAMI, !Ref FlumeImageAMI, !FindInMap [RegionMap, !Ref "AWS::Region", !Ref FlumeProcessorArchitecture]]
        InstanceType: !If [ IsArm, r6g.large, 5ad.large ]
        TagSpecifications:
          - ResourceType: instance
            Tags:
              - Key: Name
                Value: !Sub "${AWS::StackName}-Flume"
          - ResourceType: volume
            Tags:
              - Key: Name
                Value: !Sub "${AWS::StackName}-Flume"
        SecurityGroupIds:
          - !Sub ${FlumeNodeSecurityGroup.GroupId}
          - !If [HasExtraSecurityGroup, !Ref FlumeExtraSecurityGroup, !Ref 'AWS::NoValue']
        IamInstanceProfile:
          Name: !Ref FlumeNodeInstanceProfile
        KeyName: !If [HasKeyName, !Ref KeyName, !Ref 'AWS::NoValue']
        CreditSpecification: !If [SmallFlume, {CpuCredits: standard}, !Ref 'AWS::NoValue']
        BlockDeviceMappings:
        - DeviceName: "/dev/sdf"
          Ebs:
            VolumeSize: !Ref FlumeDiskSize
            VolumeType: gp3
            Iops: 4000
            Throughput: 1000
        - DeviceName: "/dev/sds"
          Ebs:
            VolumeSize: 8
            VolumeType: gp3
            Iops: 3000
            Throughput: 125

        UserData:
          "Fn::Base64":
            "Fn::Sub":
              - |
                #!/bin/bash -xe
                curl https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-py3-latest.tar.gz --output - | tar xzf -
                export PYTHONPATH=aws-cfn-bootstrap-2.0/
                export PATH=$PATH:aws-cfn-bootstrap-2.0/bin/
                chmod +x aws-cfn-bootstrap-2.0/bin/cfn-init

                apt update
                apt install -y jq unzip sqlite3

                curl "https://awscli.amazonaws.com/awscli-exe-linux-$(arch).zip" -o "awscliv2.zip"
                unzip awscliv2.zip
                ./aws/install

                if [ "$(arch)" == "x86_64" ]
                then
                  ARCH="amd64"
                elif [ "$(arch)" == "aarch64" ]
                then
                  ARCH="arm64"
                fi
                useradd -r flume
                LOGS_BIN="journald-cloudwatch-logs-$ARCH"
                aws s3 cp s3://${S3ECBucketName}/$LOGS_BIN /usr/local/bin/journald-cloudwatch-logs
                chmod +x /usr/local/bin/journald-cloudwatch-logs
                mkdir -p /var/lib/journald-cloudwatch-logs/
                wget https://s3.amazonaws.com/amazoncloudwatch-agent/ubuntu/$ARCH/latest/amazon-cloudwatch-agent.deb
                dpkg -i amazon-cloudwatch-agent.deb

                /usr/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c ssm:${MetricsConfigParameter} -s

                printf "[Unit]\nDescription=journald-cloudwatch-logs\nWants=basic.target\nAfter=basic.target network.target\n\n[Service]\nExecStart=/usr/local/bin/journald-cloudwatch-logs /usr/local/etc/journald-cloudwatch-logs.conf\nKillMode=process\nRestart=on-failure\nRestartSec=42s" > /etc/systemd/system/journald-cloudwatch-logs.service

                printf "log_group = \"${FlumeLG}\"\nstate_file = \"/var/lib/journald-cloudwatch-logs/state\"" > /usr/local/etc/journald-cloudwatch-logs.conf
                mkdir -p /var/lib/flume
                export AWS_DEFAULT_REGION=${AWS::Region}

                printf 'import subprocess
                import sys
                import json
                import requests
                instance_id = requests.get("http://169.254.169.254/2012-01-12/meta-data/instance-id").text
                x = subprocess.Popen(["aws", "ec2", "describe-volumes", "--region", "${AWS::Region}", "--filters", "Name=attachment.instance-id,Values=" + instance_id, "--query", "Volumes[].Attachments[].[Device,VolumeId]", "--output", "json"], stdout=subprocess.PIPE)
                y = {k: v for k, v in json.load(x.stdout)}
                z = {line.split()[1]: line.split()[0] for line in subprocess.Popen(["lsblk", "-o", "NAME,SERIAL"], stdout=subprocess.PIPE).stdout.readlines() if len(line.split()) == 2}
                for dest,vol in y.items():
                  print (z[vol.replace("-","").encode("utf8")].decode("utf8"),dest)
                  subprocess.Popen(["ln","-s","/dev/"+z[vol.replace("-","").encode("utf8")].decode("utf8"),dest], stdout=subprocess.PIPE)
                ' > /tmp/setvolumes.py
                python3 /tmp/setvolumes.py

                mkswap /dev/sds
                swapon /dev/sds

                if [ -e /dev/sdf ]
                then
                  mkfs.ext4 /dev/sdf
                  mount -o barrier=0,data=writeback /dev/sdf /var/lib/flume
                  echo "/dev/sdf  /var/lib/flume    ext4   barrier=0,data=writeback,noatime  1   1" >> /etc/fstab
                fi

                # Disable NVME logic for now
                # ignore="$(readlink -f /dev/sd*) $(readlink -f /dev/xvd*)"
                # cutignore="$(for x in $ignore ; do echo $x | cut -c -12; done | uniq)"
                # devices="$(ls /dev/nvme* | grep -E 'n1$')"
                # cutdevices="$(for x in $devices ; do echo $x | cut -c -12; done | uniq)"
                # localnvme=$(for d in $cutdevices; do if ! $(echo "$cutignore"| grep -q $d) ; then echo $d; fi ; done)
                # if [ ! -z "$localnvme" ]
                # then
                #   mkfs.ext4 $localnvme
                #   mount -o barrier=0,data=writeback $localnvme /var/lib/flume
                #   echo "$localnvme  /var/lib/flume    ext4   barrier=0,data=writeback,noatime  1   1" >> /etc/fstab
                # fi

                echo "flume        hard nofile 500000" >> /etc/security/limits.conf
                echo "flume        soft nofile 500000" >> /etc/security/limits.conf

                printf '### IMPROVE SYSTEM MEMORY MANAGEMENT ###

                # Increase size of file handles and inode cache
                fs.file-max = 2097152

                # Do less swapping
                vm.swappiness = 10
                vm.dirty_ratio = 60
                vm.dirty_background_ratio = 2

                ### GENERAL NETWORK SECURITY OPTIONS ###

                # Number of times SYNACKs for passive TCP connection.
                net.ipv4.tcp_synack_retries = 2

                # Allowed local port range
                net.ipv4.ip_local_port_range = 2000 65535

                # Protect Against TCP Time-Wait
                net.ipv4.tcp_rfc1337 = 1

                # Decrease the time default value for tcp_fin_timeout connection
                net.ipv4.tcp_fin_timeout = 15

                # Decrease the time default value for connections to keep alive
                net.ipv4.tcp_keepalive_time = 300
                net.ipv4.tcp_keepalive_probes = 5
                net.ipv4.tcp_keepalive_intvl = 15

                ### TUNING NETWORK PERFORMANCE ###

                # Default Socket Receive Buffer
                net.core.rmem_default = 31457280

                # Maximum Socket Receive Buffer
                net.core.rmem_max = 12582912

                # Default Socket Send Buffer
                net.core.wmem_default = 31457280

                # Maximum Socket Send Buffer
                net.core.wmem_max = 12582912

                # Increase number of incoming connections
                net.core.somaxconn = 4096

                # Increase number of incoming connections backlog
                net.core.netdev_max_backlog = 65536

                # Increase the maximum amount of option memory buffers
                net.core.optmem_max = 25165824

                # Increase the maximum total buffer-space allocatable
                # This is measured in units of pages (4096 bytes)
                net.ipv4.tcp_mem = 65536 131072 262144
                net.ipv4.udp_mem = 65536 131072 262144

                # Increase the read-buffer space allocatable
                net.ipv4.tcp_rmem = 8192 87380 16777216
                net.ipv4.udp_rmem_min = 16384

                # Increase the write-buffer-space allocatable
                net.ipv4.tcp_wmem = 8192 65536 16777216
                net.ipv4.udp_wmem_min = 16384

                # Increase the tcp-time-wait buckets pool size to prevent simple DOS attacks
                net.ipv4.tcp_max_tw_buckets = 1440000
                net.ipv4.tcp_tw_recycle = 1
                net.ipv4.tcp_tw_reuse = 1' > /etc/sysctl.conf

                sysctl -p || true

                crontab -l >  newcrontab || true
                echo "5,20,35,50 * * * * /usr/bin/sh -c 'for x in \$(ls /dev/sd*) ; do echo resizing \$(readlink -f \$x) if needed; /usr/sbin/resize2fs \$(readlink -f \$x) ; done'" >> newcrontab
                crontab newcrontab

                #Copy Down flumeserver
                if ! aws s3 cp s3://${S3ECBucketName}/${S3FlumeBinaryDirectory}/flumeserver-$ARCH /usr/bin/flumeserver
                then
                  if [ "${AggregatedNotifications}" != "" ]
                    then
                    aws sns publish --topic-arn=${AggregatedNotifications} --subject="${AWS::StackName} - CRITICAL Failure to pull binary" --message="Flume failed to pull down the binary for cluster '${AWS::StackName}'. Correct permssions/upload as soon as possible."
                  fi
                  if [ "${AlarmSNSTopic}" != "" ]
                    then
                    aws sns publish --topic-arn=${AlarmSNSTopic} --subject="${AWS::StackName} - CRITICAL Failure to pull binary" --message="Flume failed to pull down the binary for cluster '${AWS::StackName}'. Correct permssions/upload as soon as possible."
                  fi
                  poweroff
                fi
                chmod +x /usr/bin/flumeserver

                aws s3 cp s3://${S3ECBucketName}/backupmanager/v0.1.3/backupmanager-linux-$ARCH /usr/bin/backupmanager
                chmod +x /usr/bin/backupmanager

                totalm=$(free -m | awk '/^Mem:/{print $2}') ; echo $totalm
                concurrency=$((totalm / 1600 ))

                export AWS_REGION=${AWS::Region}
                #copy down the flume backup
                if ! backupmanager download --concurrency=$concurrency s3://${S3FlumeBackup} /var/lib/flume/item.sqlite
                then
                  if [ "${AggregatedNotifications}" != "" ]
                    then
                    aws sns publish --topic-arn=${AggregatedNotifications} --subject="${AWS::StackName} - CRITICAL Failure to pull backup" --message="Flume failed to pull down the database backup for cluster '${AWS::StackName}'. Correct permssions/upload as soon as possible."
                  fi
                  if [ "${AlarmSNSTopic}" != "" ]
                    then
                    aws sns publish --topic-arn=${AlarmSNSTopic} --subject="${AWS::StackName} - CRITICAL Failure to pull backup" --message="Flume failed to pull down the database backup for cluster '${AWS::StackName}'. Correct permssions/upload as soon as possible."
                  fi
                  poweroff
                fi
                chown -R flume /var/lib/flume

                printf "[Unit]
                Description=Flume getlogs go client
                After=syslog.target network.target
                [Service]
                User=flume
                Group=flume
                Environment=HOME=/var/lib/flume
                Type=simple
                LimitNOFILE=655360
                ExecStart=/usr/bin/flumeserver ${RollbackFlag} ${FlumeNetworkFlag} --reorg-threshold ${FlumeReorgThreshold} /var/lib/flume/item.sqlite \"${FlumeSyncEndpoint}\"
                CPUSchedulingPolicy=fifo
                CPUSchedulingPriority=20
                KillMode=process
                KillSignal=SIGINT
                TimeoutStopSec=90
                Restart=on-failure
                TimeoutStartSec=86400
                RestartSec=10s
                [Install]
                WantedBy=multi-user.target
                " > /etc/systemd/system/flume.service

                aws-cfn-bootstrap-2.0/bin/cfn-init -v --stack ${AWS::StackName} --resource FlumeLaunchTemplate --configsets cs_install --region ${AWS::Region}
                systemctl daemon-reload
                systemctl enable flume.service
                systemctl enable amazon-cloudwatch-agent.service
                systemctl start amazon-cloudwatch-agent.service
                systemctl enable journald-cloudwatch-logs
                systemctl start journald-cloudwatch-logs
                systemctl start flume.service

                sleep 300
                VOLUME_ID=$(aws ec2 describe-volumes --filters Name=attachment.instance-id,Values="$(curl http://169.254.169.254/latest/meta-data/instance-id)" | jq '.Volumes[] | select(. | .Attachments[0].Device == "/dev/sdf") | .VolumeId' -cr)
                aws ec2 modify-volume --volume-id $VOLUME_ID --volume-type gp3 --iops ${FlumeDiskIOPS} --throughput 125 &
              - ClusterId:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-ClusterId"
                BaseInfrastructure:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-BaseInfrastructure"
                RollbackFlag: !If [ HasRollback, !Sub "--kafka-rollback=${FlumeKafkaRollback}", ""]
  FlumeAutoScalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      VPCZoneIdentifier:
        - "Fn::ImportValue":
            !Sub "${InfrastructureStack}-PublicA"
        - "Fn::ImportValue":
            !Sub "${InfrastructureStack}-PublicB"
        - "Fn::ImportValue":
            !Sub "${InfrastructureStack}-PublicC"
      MixedInstancesPolicy:
        InstancesDistribution:
          SpotAllocationStrategy: !Ref FlumeSpotAllocationStrategy
          OnDemandPercentageAboveBaseCapacity: !Ref FlumeOnDemandPercentage
          SpotInstancePools: !If [ FlumeSpotLowestPrice, !FindInMap [PoolSize, !Ref FlumeProcessorArchitecture, !Ref FlumeSize], !Ref "AWS::NoValue"]
        LaunchTemplate:
          LaunchTemplateSpecification:
            LaunchTemplateId: !Ref FlumeLaunchTemplate
            Version: !Sub ${FlumeLaunchTemplate.LatestVersionNumber}
          Overrides: !FindInMap [InstanceSizes, !Ref FlumeProcessorArchitecture, !Ref FlumeSize]
      MinSize: !Ref FlumeTargetCapacity
      MaxSize: !Ref FlumeMaxCapacity
      HealthCheckType: EC2
      TargetGroupARNs: !If [HasATG, !Split [",", !Ref FlumeAlternateTargetGroup ], !Ref "AWS::NoValue" ]
      MetricsCollection:
      - Granularity: 1Minute
        Metrics:
        - GroupInServiceInstances
      Tags:
      - Key: Name
        Value: !Sub ${AWS::StackName}-Flume
        PropagateAtLaunch: 'true'
  FlumeSnapshotLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        ImageId: !If [HasFlumeImageAMI, !Ref FlumeImageAMI, !FindInMap [RegionMap, !Ref "AWS::Region", "arm64" ]]
        InstanceType: r6g.large
        TagSpecifications:
          - ResourceType: instance
            Tags:
              - Key: Name
                Value: !Sub "${AWS::StackName}-FlumeSnapshot"
          - ResourceType: volume
            Tags:
              - Key: Name
                Value: !Sub "${AWS::StackName}-FlumeSnapshot"
        SecurityGroupIds:
          - !Sub ${FlumeNodeSecurityGroup.GroupId}
        IamInstanceProfile:
          Name: !Ref FlumeSnapshotNodeInstanceProfile
        KeyName: !If [HasKeyName, !Ref KeyName, !Ref 'AWS::NoValue']
        # CreditSpecification:
        #   CpuCredits: standard
        InstanceInitiatedShutdownBehavior: terminate
        BlockDeviceMappings:
        # - DeviceName: "/dev/sdf"
        #   Ebs:
        #     VolumeSize: !Ref FlumeDiskSize
        #     VolumeType: gp3
        #     Iops: 4000
        #     Throughput: 1000
        - DeviceName: "/dev/sds"
          Ebs:
            VolumeSize: 8
            VolumeType: gp3
            Iops: 3000
            Throughput: 125

        UserData:
          "Fn::Base64":
            "Fn::Sub":
              - |
                #!/bin/bash -xe
                if [ "$(arch)" == "x86_64" ]
                then
                  ARCH="amd64"
                elif [ "$(arch)" == "aarch64" ]
                then
                  ARCH="arm64"
                fi
                LOGS_BIN="journald-cloudwatch-logs-$ARCH"

                apt update
                apt install -y jq sqlite3 unzip

                curl "https://awscli.amazonaws.com/awscli-exe-linux-$(arch).zip" -o "awscliv2.zip"

                unzip awscliv2.zip
                ./aws/install

                AVAILABILITY_ZONE=$(curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone)
                INSTANCE_ID=$(curl -s http://169.254.169.254/2012-01-12/meta-data/instance-id)

                VOLUME_ID=$(aws ec2 describe-volumes --filters Name=tag:SnapshotVolume,Values=${AWS::StackName}-${AWS::Region} Name=status,Values=available Name=availability-zone,Values=$AVAILABILITY_ZONE | jq -r .Volumes[0].VolumeId)

                if [ "$VOLUME_ID" == "null"  ]
                then
                  VOLUME_CREATED="yes"
                  VOLUME_ID=$(aws ec2 create-volume --availability-zone $AVAILABILITY_ZONE --iops 4000  --throughput 1000 --size ${FlumeDiskSize} --volume-type gp3 --tag-specifications '{"ResourceType": "volume", "Tags": [{"Key": "SnapshotVolume","Value": "${AWS::StackName}-${AWS::Region}"}, {"Key": "Name", "Value": "${AWS::StackName}-SnapshotVolume"}]}' | jq -r .VolumeId)
                  while [ "$(aws ec2 describe-volumes --volume-id $VOLUME_ID | jq -r .Volumes[0].State)" != "available" ]
                  do
                    sleep 3
                  done
                fi
                aws ec2 attach-volume --device=/dev/sdf --instance-id=$INSTANCE_ID --volume-id=$VOLUME_ID
                sleep 10 # Give the volume a moment to register with the kernel

                while [ "$(aws ec2 describe-volumes --volume-id $VOLUME_ID | jq -r .Volumes[0].State)" != "in-use" ]
                do
                  sleep 3
                done

                mkdir -p /var/lib/flume

                printf 'import subprocess
                import sys
                import json
                import requests
                instance_id = requests.get("http://169.254.169.254/2012-01-12/meta-data/instance-id").text
                x = subprocess.Popen(["aws", "ec2", "describe-volumes", "--region", "${AWS::Region}", "--filters", "Name=attachment.instance-id,Values=" + instance_id, "--query", "Volumes[].Attachments[].[Device,VolumeId]", "--output", "json"], stdout=subprocess.PIPE)
                y = {k: v for k, v in json.load(x.stdout)}
                z = {line.split()[1]: line.split()[0] for line in subprocess.Popen(["lsblk", "-o", "NAME,SERIAL"], stdout=subprocess.PIPE).stdout.readlines() if len(line.split()) == 2}
                for dest,vol in y.items():
                  print (z[vol.replace("-","").encode("utf8")].decode("utf8"),dest)
                  subprocess.Popen(["ln","-s","/dev/"+z[vol.replace("-","").encode("utf8")].decode("utf8"),dest], stdout=subprocess.PIPE)
                ' > /tmp/setvolumes.py
                python3 /tmp/setvolumes.py

                if [ "$VOLUME_CREATED" == "yes" ]
                then
                  mkfs.ext4 /dev/sdf
                fi

                mkswap /dev/sds
                swapon /dev/sds

                if [ -e /dev/sdf ]
                then
                  mount -o barrier=0,data=writeback /dev/sdf /var/lib/flume
                  echo "/dev/sdf  /var/lib/flume    ext4   barrier=0,data=writeback,noatime  1   1" >> /etc/fstab
                fi

                resize2fs /dev/sdf

                export AWS_DEFAULT_REGION=${AWS::Region}

                # Ignore NVME for now
                # ignore="$(readlink -f /dev/sd*) $(readlink -f /dev/xvd*)"
                # cutignore="$(for x in $ignore ; do echo $x | cut -c -12; done | uniq)"
                # devices="$(ls /dev/nvme* | grep -E 'n1$')"
                # cutdevices="$(for x in $devices ; do echo $x | cut -c -12; done | uniq)"
                # localnvme=$(for d in $cutdevices; do if ! $(echo "$cutignore"| grep -q $d) ; then echo $d; fi ; done)
                # if [ ! -z "$localnvme" ]
                # then
                #   mkfs.ext4 $localnvme
                #   mount -o barrier=0,data=writeback $localnvme /var/lib/flume
                #   echo "$localnvme  /var/lib/flume    ext4   barrier=0,data=writeback,noatime  1   1" >> /etc/fstab
                # fi


                printf '### IMPROVE SYSTEM MEMORY MANAGEMENT ###

                # Increase size of file handles and inode cache
                fs.file-max = 2097152

                # Do less swapping
                vm.swappiness = 10
                vm.dirty_ratio = 60
                vm.dirty_background_ratio = 2

                ### GENERAL NETWORK SECURITY OPTIONS ###

                # Number of times SYNACKs for passive TCP connection.
                net.ipv4.tcp_synack_retries = 2

                # Allowed local port range
                net.ipv4.ip_local_port_range = 2000 65535

                # Protect Against TCP Time-Wait
                net.ipv4.tcp_rfc1337 = 1

                # Decrease the time default value for tcp_fin_timeout connection
                net.ipv4.tcp_fin_timeout = 15

                # Decrease the time default value for connections to keep alive
                net.ipv4.tcp_keepalive_time = 300
                net.ipv4.tcp_keepalive_probes = 5
                net.ipv4.tcp_keepalive_intvl = 15

                ### TUNING NETWORK PERFORMANCE ###

                # Default Socket Receive Buffer
                net.core.rmem_default = 31457280

                # Maximum Socket Receive Buffer
                net.core.rmem_max = 12582912

                # Default Socket Send Buffer
                net.core.wmem_default = 31457280

                # Maximum Socket Send Buffer
                net.core.wmem_max = 12582912

                # Increase number of incoming connections
                net.core.somaxconn = 4096

                # Increase number of incoming connections backlog
                net.core.netdev_max_backlog = 65536

                # Increase the maximum amount of option memory buffers
                net.core.optmem_max = 25165824

                # Increase the maximum total buffer-space allocatable
                # This is measured in units of pages (4096 bytes)
                net.ipv4.tcp_mem = 65536 131072 262144
                net.ipv4.udp_mem = 65536 131072 262144

                # Increase the read-buffer space allocatable
                net.ipv4.tcp_rmem = 8192 87380 16777216
                net.ipv4.udp_rmem_min = 16384

                # Increase the write-buffer-space allocatable
                net.ipv4.tcp_wmem = 8192 65536 16777216
                net.ipv4.udp_wmem_min = 16384

                # Increase the tcp-time-wait buckets pool size to prevent simple DOS attacks
                net.ipv4.tcp_max_tw_buckets = 1440000
                net.ipv4.tcp_tw_recycle = 1
                net.ipv4.tcp_tw_reuse = 1' > /etc/sysctl.conf

                sysctl -p || true

                #Copy Down flumeserver
                if ! aws s3 cp s3://${S3ECBucketName}/${S3FlumeBinaryDirectory}/flumeserver-$ARCH /usr/bin/flumeserver
                then
                  if [ "${AggregatedNotifications}" != "" ]
                    then
                    aws sns publish --topic-arn=${AggregatedNotifications} --subject="${AWS::StackName} - CRITICAL Failure to pull binary" --message="Flume failed to pull down the binary for cluster '${AWS::StackName}'. Correct permssions/upload as soon as possible."
                  fi
                  if [ "${AlarmSNSTopic}" != "" ]
                    then
                    aws sns publish --topic-arn=${AlarmSNSTopic} --subject="${AWS::StackName} - CRITICAL Failure to pull binary" --message="Flume failed to pull down the binary for cluster '${AWS::StackName}'. Correct permssions/upload as soon as possible."
                  fi
                  poweroff
                fi
                chmod +x /usr/bin/flumeserver

                aws s3 cp s3://${S3ECBucketName}/backupmanager/v0.1.3/backupmanager-linux-$ARCH /usr/bin/backupmanager
                chmod +x /usr/bin/backupmanager

                sysctl -w net.ipv4.tcp_mem='10000000 10000000 10000000'

                # Set the receive buffer for each TCP connection with minumum, default and maximum thresholds
                sysctl -w net.ipv4.tcp_rmem='1024 4096 16384'

                # Set the TCP send buffer space with minumum, default and maximum thresholds
                sysctl -w net.ipv4.tcp_wmem='1024 4096 16384'

                # The maximum socket receive buffer sizemem_max=16384
                sysctl -w net.core.rmem_max=16384

                # The maximum socket send buffer size
                sysctl -w net.core.wmem_max=16384

                sysctl -w vm.swappiness=0

                export AWS_REGION=${AWS::Region}

                totalm=$(free -m | awk '/^Mem:/{print $2}') ; echo $totalm
                concurrency=$((totalm / 1600 ))

                if [ ! -f /var/lib/flume/item.sqlite ]
                then
                  #copy down the flume backup
                  if ! backupmanager download --concurrency=$concurrency s3://${S3FlumeBackup} /var/lib/flume/item.sqlite
                  then
                    if [ "${AggregatedNotifications}" != "" ]
                      then
                      aws sns publish --topic-arn=${AggregatedNotifications} --subject="${AWS::StackName} - CRITICAL Failure to pull backup" --message="Flume failed to pull down the database backup for cluster '${AWS::StackName}'. Correct permssions/upload as soon as possible."
                    fi
                    if [ "${AlarmSNSTopic}" != "" ]
                      then
                      aws sns publish --topic-arn=${AlarmSNSTopic} --subject="${AWS::StackName} - CRITICAL Failure to pull backup" --message="Flume failed to pull down the database backup for cluster '${AWS::StackName}'. Correct permssions/upload as soon as possible."
                    fi
                    poweroff
                  fi
                fi

                if [ -f /tmp/pre-sync.sql ]
                then
                  if ! cat /tmp/pre-sync.sql | sqlite3 /var/lib/flume/item.sqlite
                  then
                    touch /tmp/interactive
                  fi
                fi
                if [ -f /tmp/interactive ]
                then
                  if [ "${AlarmSNSTopic}" != "" ]
                    then
                    aws sns publish --topic-arn=${AlarmSNSTopic} --subject="${AWS::StackName} - Flume Backup: Interactive Session Ready" --message="The flume snapshotter on stack '${AWS::StackName}' is waiting for operator input. The hostname is $(hostname)."
                  fi
                  if [ "${AggregatedNotifications}" != "" ]
                    then
                    aws sns publish --topic-arn=${AggregatedNotifications} --subject="${AWS::StackName} - Flume Backup: Interactive Session Ready" --message="The flume snapshotter on stack '${AWS::StackName}' is waiting for operator input. The hostname is $(hostname)."
                  fi
                fi

                while [ -f /tmp/interactive ]
                do
                  sleep 30
                done

                #Deal with double escapes in url if exist
                printf "/usr/bin/flumeserver ${RollbackFlag} --reorg-threshold ${FlumeReorgThreshold} -shutdown.sync /var/lib/flume/item.sqlite \"${FlumeSyncEndpoint}\"" > /tmp/flumesync.sh
                chmod +x /tmp/flumesync.sh

                # sync and shutdown
                if ! /tmp/flumesync.sh
                then
                  if [ "${AggregatedNotifications}" != "" ]
                  then
                    aws sns publish --topic-arn=${AggregatedNotifications} --subject="${AWS::StackName} - ${AWS::Region} - Snapshot Failed to Sync" --message="Flume sync failed while taking snapshot for cluster '${AWS::StackName}'. No snapshot will be taken. ]"
                  fi
                  if [ "${AlarmSNSTopic}" != "" ]
                  then
                    aws sns publish --topic-arn=${AlarmSNSTopic} --subject="${AWS::StackName} - ${AWS::Region} -  Snapshot Failed to Sync" --message="Flume sync failed while taking snapshot for cluster '${AWS::StackName}'. No snapshot will be taken. ]"
                  fi
                  poweroff
                  exit 1
                fi

                if [ -f /tmp/post-sync.sql ]
                then
                  if ! cat /tmp/post-sync.sql | sqlite3 /var/lib/flume/item.sqlite
                  then
                    touch /tmp/interactive
                  fi
                fi
                if [ -f /tmp/interactive ]
                then
                  if [ "${AlarmSNSTopic}" != "" ]
                    then
                    aws sns publish --topic-arn=${AlarmSNSTopic} --subject="${AWS::StackName} - Flume Backup: Interactive Session Ready" --message="The flume snapshotter on stack '${AWS::StackName}' is waiting for operator input. The hostname is $(hostname)."
                  fi
                  if [ "${AggregatedNotifications}" != "" ]
                    then
                    aws sns publish --topic-arn=${AggregatedNotifications} --subject="${AWS::StackName} - Flume Backup: Interactive Session Ready" --message="The flume snapshotter on stack '${AWS::StackName}' is waiting for operator input. The hostname is $(hostname)."
                  fi
                fi

                while [ -f /tmp/interactive ]
                do
                  sleep 30
                done

                # upload Backup
                export BACKUPNAME="${S3FlumeBackupBucket}/${NetworkId}/flume-$(date '+%Y%m%d-%H%M%S').sqlite"
                if ! backupmanager upload --concurrency=$concurrency /var/lib/flume/item.sqlite s3://$BACKUPNAME; then
                  if [ "${AggregatedNotifications}" != "" ]
                  then
                    aws sns publish --topic-arn=${AggregatedNotifications} --subject="${AWS::StackName} - Taking Backup Failed" --message="The snapshotting process for ${AWS::StackName} failed to upload the backup."
                  fi
                  if [ "${AlarmSNSTopic}" != "" ]
                  then
                    aws sns publish --topic-arn=${AlarmSNSTopic} --subject="${AWS::StackName} - Taking Backup Failed" --message="The snapshotting process for ${AWS::StackName} failed to upload the backup."
                  fi
                  poweroff
                  exit 1
                fi

                # CFN will set any parameters we don't provide back to their default values,
                # so get all of the parameters, update S3FlumeBackup, and update the stack with
                # the new parameters.
                PARAMETERS=$(aws cloudformation describe-stacks --stack-name ${AWS::StackName} | jq '.Stacks[0].Parameters | map(if .ParameterKey == "S3FlumeBackup" then .ParameterValue="'$BACKUPNAME'" else . end) | map(if .ParameterKey == "SnapshotTimestamp" then .ParameterValue="'$(date +%s)'" else . end)' -c)


                # Resize Disks
                ORIGINAL_DISK_SIZE=`aws ec2 describe-volumes --volume-ids "$VOLUME_ID" | jq '.Volumes[] | .Size' -cr`
                NEW_DISK_SIZE=$((ORIGINAL_DISK_SIZE*115/100))

                ## manually grepping for sdf (mount direcotry above) because we don't really need to worry about the others.
                df -H | grep -vE '^Filesystem|tmpfs|cdrom' | grep $(readlink -f /dev/sdf) | awk '{ print $5 " " $1 }' | while read output;
                do
                  echo $output
                  usep=$(echo $output | awk '{ print $1}' | cut -d'%' -f1  )
                  partition=$(echo $output | awk '{ print $2 }' )
                  if [ $usep -ge 90 ]; then
                    if [ "${AggregatedNotifications}" != "" ]
                    then
                      aws sns publish --topic-arn=${AggregatedNotifications} --subject="${AWS::StackName} - Upsizing Snapshot Size" --message="The snapshot for ${AWS::StackName} has reached $usep%. Resizing to $NEW_DISK_SIZE GB."
                      if [ "${AlarmSNSTopic}" != "" ]
                      then
                        aws sns publish --topic-arn=${AlarmSNSTopic} --subject="${AWS::StackName} - Upsizing Snapshot Size" --message="The snapshot for ${AWS::StackName} has reached $usep%. Resizing to $NEW_DISK_SIZE GB."
                      fi
                      PARAMETERS_RESIZE=$(echo "$PARAMETERS" | jq 'map(if .ParameterKey == "FlumeDiskSize" then .ParameterValue="'$NEW_DISK_SIZE'" else . end)' -c)
                      aws cloudformation update-stack --stack-name ${AWS::StackName} --use-previous-template --capabilities CAPABILITY_IAM --parameters="$PARAMETERS_RESIZE"
                    fi
                    else
                      aws cloudformation update-stack --stack-name ${AWS::StackName} --use-previous-template --capabilities CAPABILITY_IAM --parameters="$PARAMETERS"
                  fi

                done
                if [ "$VOLUME_CREATED" == "yes" ]
                then
                  aws ec2 modify-volume --volume-id $VOLUME_ID --volume-type gp3 --iops 3000 --throughput 125 &
                fi
                poweroff
                exit 1
              - ClusterId:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-ClusterId"
                RollbackFlag: !If [ HasRollback, !Sub "--kafka-rollback=${FlumeKafkaRollback}", ""]

  FlumeSnapshotNodeRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
            - autoscaling.amazonaws.com
        Version: '2012-10-17'
  FlumeSnapshotNodePolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref FlumeSnapshotNodeRole
      PolicyName: !Sub "FlumeSnapshotNode${AWS::StackName}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Action:
              - s3:GetObject
              - s3:ListBucket
              - s3:GetBucketPolicy
              - s3:GetObjectTagging
              - s3:GetBucketLocation
              - s3:PutObject
            Resource:
              - !Sub arn:aws:s3:::${S3FlumeBackupBucket}
              - !Sub arn:aws:s3:::${S3FlumeBackupBucket}/*
            Effect: Allow
          - Action:
              - s3:GetObject
              - s3:ListBucket
              - s3:GetBucketPolicy
              - s3:GetObjectTagging
              - s3:GetBucketLocation
            Resource:
              - !Sub arn:aws:s3:::${S3ECBucketName}
              - !Sub arn:aws:s3:::${S3ECBucketName}/*
            Effect: Allow
          - Action:
              - s3:GetObject
              - s3:ListBucket
              - s3:GetBucketPolicy
              - s3:GetObjectTagging
              - s3:GetBucketLocation
            Resource:
              - !Sub arn:aws:s3:::${CurrentBackupBucket.Name}
              - !Sub arn:aws:s3:::${S3FlumeBackup}/*
            Effect: Allow
          - Action:
              - cloudformation:UpdateStack
            Resource: !Sub "arn:aws:cloudformation:${AWS::Region}:${AWS::AccountId}:stack/${AWS::StackName}/*"
            Effect: Allow
          - Action:
              - iam:GetInstanceProfile
            Resource:
              - !Sub ${FlumeNodeInstanceProfile.Arn}
              - !Sub ${FlumeSnapshotNodeInstanceProfile.Arn}
              - !Sub ${BackupGCRole.Arn}
            Effect: Allow
          - Action:
              - lambda:UpdateFunctionConfiguration
              - lambda:InvokeFunction
              - lambda:InvokeAsync
              - lambda:GetFunctionConfiguration
              - lambda:GetFunction
            Resource:
              - !Sub ${FlumeSnapshotLambdaFunction.Arn}
              - !Sub ${GetBucketName.Arn}
              - !Sub ${FlumeBackupGCFunction.Arn}
              - !Sub ${DiskSizeLambdaFunction.Arn}
              - !Sub ${SnapDiskSizeLambdaFunction.Arn}
            Effect: Allow
          - Action:
              - iam:PassRole
              - iam:GetRole
              - iam:PutRolePolicy
            Resource:
              - !Sub "${FlumeNodeRole.Arn}"
              - !Sub "${FlumeSnapshotLambdaRole.Arn}"
              - !Sub "${FlumeSnapshotNodeRole.Arn}"
              - !Sub "${BackupGCRole.Arn}"
              - !Sub ${DiskSizeLambdaRole.Arn}
            Effect: Allow
          - Action:
              - sns:Publish
            Resource:
              - !Ref AggregatedNotifications
              - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
            Effect: Allow
          - Action:
              - autoscaling:EnableMetricsCollection
              - autoscaling:DisableMetricsCollection
              - autoscaling:UpdateAutoScalingGroup
            Resource:
              - "*"
            Condition:
              StringEquals:
                "autoscaling:ResourceTag/aws:cloudformation:stack-id": !Sub "${AWS::StackId}"
            Effect: Allow
          - Action:
              - cloudwatch:PutMetricAlarm
            Resource:
              - !Sub "${SnapshotAgeWarning.Arn}"
            Effect: Allow
          - Action:
              - cloudformation:DescribeStacks
              - ec2:DescribeLaunchTemplates
              - ec2:DescribeSnapshotAttribute
              - ec2:CreateTags
              - ec2:DescribeLaunchTemplateVersions
              - ec2:RunInstances
              - ec2:DescribeSnapshots
              - ec2:CreateLaunchTemplateVersion
              - ec2:DescribeVolumeStatus
              - autoscaling:DescribeAutoScalingGroups
              - autoscaling:DescribeScalingActivities
              - ec2:DescribeVolumes
              - ec2:AttachVolume
              - ec2:CreateVolume
              - ec2:ModifyVolume
              - ec2:CreateSnapshot
              - ec2:DeleteSnapshot
              - events:DescribeRule
              - ec2:DescribeKeyPairs
              - cloudwatch:DescribeAlarms
            Resource: "*"
            Effect: Allow
  FlumeSnapshotNodeInstanceProfile:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      Path: /
      Roles:
      - !Ref FlumeSnapshotNodeRole
    DependsOn: FlumeSnapshotNodeRole
  FlumeSnapshotLambdaRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
        Version: '2012-10-17'
  FlumeSnapshotLambdaPolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref FlumeSnapshotLambdaRole
      PolicyName: !Sub "FlumeSnapshotLambdaPolicy${AWS::StackName}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Action:
              - logs:CreateLogStream
              - logs:CreateLogGroup
              - logs:PutLogEvents
            Effect: Allow
            Resource: "*"
          - Effect: Allow
            Action:
              - iam:PassRole
            Resource: !Sub "${FlumeSnapshotNodeRole.Arn}"
          - Effect: Allow
            Action:
              - ec2:CreateTags
              - ec2:RunInstances
            Resource:
              - Fn::Sub:
                - "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:subnet/${PublicA}"
                - PublicA:
                    "Fn::ImportValue":
                      !Sub "${InfrastructureStack}-PublicA"
              - Fn::Sub:
                - "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:subnet/${PublicB}"
                - PublicB:
                    "Fn::ImportValue":
                      !Sub "${InfrastructureStack}-PublicB"
              - Fn::Sub:
                - "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:subnet/${PublicC}"
                - PublicC:
                    "Fn::ImportValue":
                      !Sub "${InfrastructureStack}-PublicC"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:key-pair/${KeyName}"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:instance/*"

              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:volume/*"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:security-group/${FlumeNodeSecurityGroup.GroupId}"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:network-interface/*"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:launch-template/${FlumeSnapshotLaunchTemplate}"
              - "arn:aws:ec2:*::image/*"
  FlumeSnapshotLambdaFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        S3Bucket: !Ref S3ECBucketName
        S3Key: lambdaPackage-28.zip
      Description: "Launch instances to snapshot chaindata"
      Environment:
        Variables:
          LAUNCH_TEMPLATE_ID: !Ref FlumeSnapshotLaunchTemplate
          LAUNCH_TEMPLATE_VERSION: !Sub "${FlumeSnapshotLaunchTemplate.LatestVersionNumber}"
          INSTANCE_TYPES: "r6g.large,r6gd.large,m6g.xlarge,m6gd.xlarge,t4g.xlarge,c6g.xlarge,c6gd.xlarge"
          SUBNET_ID:
            "Fn::ImportValue": !Sub "${InfrastructureStack}-PublicB"
          VOLUME_SIZE: !Ref FlumeDiskSize
      Handler: "getSnapshot.handler"
      Role: !Sub ${FlumeSnapshotLambdaRole.Arn}
      Runtime: python3.7
      Timeout: 30
  SnapshotSchedulerRule:
    Type: AWS::Events::Rule
    Properties:
      Description: !Sub "Take a daily snapshot for the ${AWS::StackName} cluster"
      ScheduleExpression: !Ref FlumeSnapshotScheduleExpression
      Targets:
        - Arn: !Sub ${FlumeSnapshotLambdaFunction.Arn}
          Id: !Sub "snapshot-${AWS::StackName}"
  FlumeSnapshotInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Sub ${FlumeSnapshotLambdaFunction.Arn}
      Action: 'lambda:InvokeFunction'
      Principal: events.amazonaws.com
      SourceArn: !Sub ${SnapshotSchedulerRule.Arn}


  FlumeLogMetricsFunctionLG:
    Type: AWS::Logs::LogGroup
    Properties:
      RetentionInDays: 7
      LogGroupName: !Join ["", ["/aws/lambda/", !Ref FlumeLogMetricsFunction]]

  LogMetricsRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
        Version: '2012-10-17'
  LogMetricsFunctionPolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref LogMetricsRole
      PolicyName: !Sub "FlumeLogMetrics${AWS::StackName}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - "logs:CreateLogStream"
              - "logs:PutLogEvents"
            Resource: "*"
          - Effect: Allow
            Action:
              - "cloudwatch:PutMetricData"
            Resource: "*"
          - Effect: Allow
            Action:
              - "logs:CreateLogGroup"
            Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
  FlumeLogMetricsFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        S3Bucket: !Ref S3ECBucketName
        S3Key: flumeLambdaPackage-10.zip
      Description: "A lambda function to process Flume logs into metrics"
      Environment:
        Variables:
          CLUSTER_ID: !Sub ${NetworkId}
      Handler: "logMonitor.flumeHandler"
      Role: !Sub ${LogMetricsRole.Arn}
      Runtime: python3.7
      Timeout: 120
  FlumeLogMetricsSubscription:
    Type: AWS::Logs::SubscriptionFilter
    Properties:
      DestinationArn: !Sub ${FlumeLogMetricsFunction.Arn}
      FilterPattern: '{$.systemdUnit = "flume.service"}'
      LogGroupName: !Ref FlumeLG
  FlumeLogMetricFunctionInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Sub ${FlumeLogMetricsFunction.Arn}
      Action: 'lambda:InvokeFunction'
      Principal: !Sub logs.${AWS::Region}.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !Sub ${FlumeLG.Arn}


  BackupGCRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
        Version: '2012-10-17'
  BackupGCPolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref BackupGCRole
      PolicyName: !Sub "FlumeLogMetrics${AWS::StackName}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - sns:Publish
            Resource:
              - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
              - !If [ HasWarningWebhook, !Ref WarningNotifications, !Ref 'AWS::NoValue' ]
          - Effect: Allow
            Action:
              - "s3:ListBucket"
              - "s3:DeleteObject"
            Resource: "*"
  FlumeBackupGCFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        S3Bucket: !Ref S3ECBucketName
        S3Key: flumeLambdaPackage-8.zip
      Description: "A lambda function to process Flume logs into metrics"
      Environment:
        Variables:
          SNS_TOPICS: !Join [",", [!If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue'], !If [ HasWarningWebhook, !Ref WarningNotifications, !Ref 'AWS::NoValue' ]]]
          BACKUP_BUCKET: !Ref S3FlumeBackupBucket
          NETWORK_ID: !Ref NetworkId
          CURRENT_SNAPSHOT: !Ref S3FlumeBackup
      Handler: "flumeBackupGC.gcHandler"
      Role: !Sub ${BackupGCRole.Arn}
      Runtime: python3.7
  GCSchedulerRule:
    Type: AWS::Events::Rule
    Properties:
      Description: !Sub "Do a daily backup cleanup for ${AWS::StackName}"
      ScheduleExpression: rate(1 day)
      Targets:
        - Arn: !Sub ${FlumeBackupGCFunction.Arn}
          Id: !Sub "gc-${AWS::StackName}"
  GCInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Sub ${FlumeBackupGCFunction.Arn}
      Action: 'lambda:InvokeFunction'
      Principal: events.amazonaws.com
      SourceArn: !Sub ${GCSchedulerRule.Arn}

  DiskSizeLambdaRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
        Version: '2012-10-17'
  DiskSizeLambdaPolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref DiskSizeLambdaRole
      PolicyName: !Sub "DiskSizeLambdaPolicy${AWS::StackName}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - ec2:DescribeVolumes
              - ec2:ModifyVolume
            Resource: "*"
  DiskSizeLambdaFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        S3Bucket: !Ref S3ECBucketName
        S3Key: lambdaPackage-30.zip
      Description: "Align master volume sizes with CloudFormation parameters"
      Environment:
        Variables:
          VOLUME_SIZE: !Ref FlumeDiskSize
          VOLUME_NAME: !Sub "${AWS::StackName}-Flume"
          ATTACHMENT_DEVICE: "/dev/sdf"
      Handler: "masterVolumeManager.sizeHandler"
      Role: !Sub ${DiskSizeLambdaRole.Arn}
      Runtime: python3.7
  DiskManagerSchedulerRule:
    Type: AWS::Events::Rule
    Properties:
      Description: Disk Size manager
      ScheduleExpression: "rate(15 minutes)"
      Targets:
        - Arn: !Sub ${DiskSizeLambdaFunction.Arn}
          Id: !Sub "disk-size-${NetworkId}-${FlumeClusterVersion}"
  SnapDiskSizeLambdaFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        S3Bucket: !Ref S3ECBucketName
        S3Key: lambdaPackage-30.zip
      Description: "Align master volume sizes with CloudFormation parameters"
      Environment:
        Variables:
          VOLUME_SIZE: !Ref FlumeDiskSize
          VOLUME_NAME: !Sub "${AWS::StackName}-SnapshotVolume"
          ATTACHMENT_DEVICE: "/dev/sdf"
      Handler: "masterVolumeManager.sizeHandler"
      Role: !Sub ${DiskSizeLambdaRole.Arn}
      Runtime: python3.7
  SnapDiskManagerSchedulerRule:
    Type: AWS::Events::Rule
    Properties:
      Description: Disk Size manager
      ScheduleExpression: "rate(15 minutes)"
      Targets:
        - Arn: !Sub ${SnapDiskSizeLambdaFunction.Arn}
          Id: !Sub "disk-size-${NetworkId}-${FlumeClusterVersion}"

  DiskManagerInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Sub ${DiskSizeLambdaFunction.Arn}
      Action: 'lambda:InvokeFunction'
      Principal: events.amazonaws.com
      SourceArn: !Sub ${DiskManagerSchedulerRule.Arn}

  # TODO
  # SnapshotGCLambdaRole:
  #   Type: "AWS::IAM::Role"
  #   Properties:
  #     AssumeRolePolicyDocument:
  #       Statement:
  #       - Action:
  #         - sts:AssumeRole
  #         Effect: Allow
  #         Principal:
  #           Service:
  #           - lambda.amazonaws.com
  #       Version: '2012-10-17'
  # SnapshotGCLambdaPolicy:
  #   Type: "AWS::IAM::Policy"
  #   Properties:
  #     Roles:
  #       - !Ref SnapshotGCLambdaRole
  #     PolicyName: !Sub "SnapshotGCLambdaPolicy${AWS::StackName}"
  #     PolicyDocument:
  #       Version: 2012-10-17
  #       Statement:
  #         - Effect: Allow
  #           Action:
  #             - ec2:DescribeSnapshots
  #             - ec2:DeleteSnapshot
  #           Resource: "*"
  # SnapshotGCLambdaFunction:
  #   Type: "AWS::Lambda::Function"
  #   Properties:
  #     Code:
  #       S3Bucket: !Ref S3ECBucketName
  #       S3Key: lambdaPackage-17.zip
  #     Description: "Cleanup old chaindata snapshots"
  #     Environment:
  #       Variables:
  #         CLUSTER_ID: PLACEHOLDER #TODO
  #     Handler: "gcSnapshot.handler"
  #     Role: !Sub ${SnapshotGCLambdaRole.Arn}
  #     Runtime: python3.7
  # SnapshotGCSchedulerRule:
  #   Type: AWS::Events::Rule
  #   Properties:
  #     Description: !Sub "Cleanup old snapshots for the the ${AWS::StackName} cluster"
  #     ScheduleExpression: "rate(1 hour)"
  #     Targets:
  #       - Arn: !Sub ${SnapshotGCLambdaFunction.Arn}
  #         Id: !Sub "gc-${AWS::StackName}"
  # SnapshotGCInvokePermission:
  #   Type: AWS::Lambda::Permission
  #   Properties:
  #     FunctionName: !Sub ${SnapshotGCLambdaFunction.Arn}
  #     Action: 'lambda:InvokeFunction'
  #     Principal: events.amazonaws.com
  #     SourceArn: !Sub ${SnapshotGCSchedulerRule.Arn}

  CloudwatchDashboard:
    Type: AWS::CloudWatch::Dashboard
    Properties:
      DashboardName: !Sub "${AWS::StackName}-${AWS::Region}"
      DashboardBody:
        Fn::Sub:
          - |
              {
                "widgets": [
                    {
                        "type": "metric",
                        "x": 0,
                        "y": 6,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "AWS/EC2", "CPUUtilization", "AutoScalingGroupName", "${FlumeAutoScalingGroup}", { "stat": "Average", "label": "Flumes (avg)" } ],
                                [ "AWS/EC2", "CPUUtilization", "AutoScalingGroupName", "${FlumeAutoScalingGroup}", { "stat": "Maximum", "label": "Flumes (max)" } ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "CPU Utilization"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 6,
                        "y": 6,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "CWAgent", "disk_used_percent", "path", "/var/lib/flume", "AutoScalingGroupName", "${FlumeAutoScalingGroup}", "device", "nvme1n1", "fstype", "ext4" ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "Disk Usage"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 12,
                        "y": 6,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "CWAgent", "mem_used_percent", "AutoScalingGroupName", "${FlumeAutoScalingGroup}" , { "stat": "Average", "label": "Flumes (avg)" } ],
                                [ "CWAgent", "mem_used_percent", "AutoScalingGroupName", "${FlumeAutoScalingGroup}" , { "stat": "Maximum", "label": "Flumes (max)" } ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "Memory Utilization"
                        }
                    }
                ]
              }
          - ClusterId:
              "Fn::ImportValue": !Sub "${InfrastructureStack}-ClusterId"
